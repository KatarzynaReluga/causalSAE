% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/p_score.R
\name{p_score}
\alias{p_score}
\alias{p_score.EBLUP}
\alias{p_score.MQ}
\alias{p_score.RF}
\alias{p_score.XGB}
\title{Propensity score}
\usage{
p_score(...)

\method{p_score}{EBLUP}(obj_p_score, model_formula, ...)

\method{p_score}{MQ}(obj_p_score, model_formula, ...)

\method{p_score}{RF}(obj_p_score, model_formula, tune_RF = FALSE, ...)

\method{p_score}{XGB}(obj_p_score, model_formula, xgboost_params, ...)
}
\arguments{
\item{...}{Additional parameters.}

\item{obj_p_score}{Object defining propensity score fit.}

\item{model_formula}{Model formula.}

\item{tune_RF}{Tune parameters for fitting random forest? Default: \code{tune_RF = FALSE}.}

\item{xgboost_params}{List of parameters to obtain predictions using gradient boosting:
\itemize{
\item CV_XGB - logical variable, use cross-validation for gradient boosting? Default: \code{CV_XGB = TRUE}.
\item nfolds - number of folds in cross-validation. Default: \code{nfolds = 5}.
\item nrounds - the max number of iterations. Default: \code{nrounds = 50}.
}}
}
\description{
Fit propensity score model
}
\section{Methods (by class)}{
\itemize{
\item \code{EBLUP}: Function to estimate p_score using EBLUP

\item \code{MQ}: Function to estimate p_score using MQ

\item \code{RF}: Function to estimate p_score using RF

\item \code{XGB}: Function to estimate p_score using RF
}}

\examples{

m = 50
ni = rep(5, m)
Ni = rep(100, m)
N = sum(Ni)
n = sum(ni)

X <- generate_X(
 n = N,
 p = 1,
 covariance_norm = NULL,
 cov_type = "unif",
 seed = 1
)

X_outcome <- generate_X(
 n = N,
 p = 1,
 covariance_norm = NULL,
 cov_type = "lognorm",
 seed = 1
)

populations <- generate_pop(X, X_outcome,
                            coeffs = get_default_coeffs(),
                            errors_outcome = get_default_errors_outcome(),
                            rand_eff_outcome = get_default_rand_eff_outcome(),
                            rand_eff_p_score = get_default_rand_eff_p_score(),
                            regression_type = "continuous",
                            Ni_size  = 100,
                            m = 50,
                            no_sim = 1,
                            seed = 10)


# EBLUP

obj_p_score_EBLUP <- list(data_p_score = populations)
class(obj_p_score_EBLUP) <- "EBLUP"

ps_hat_EBLUP <-  p_score(obj_p_score = obj_p_score_EBLUP,
                         model_formula = A ~ X1 + (1|group))

# MQ

obj_p_score_MQ <- list(data_p_score = populations)
class(obj_p_score_MQ) <- "MQ"

ps_hat_MQ <-  p_score(obj_p_score = obj_p_score_MQ,
                      model_formula = A ~ X1 + (1|group))

# RF

obj_p_score_RF <- list(data_p_score = populations)
class(obj_p_score_RF) <- "RF"

ps_hat_RF <-  p_score(obj_p_score = obj_p_score_RF,
                     model_formula = A ~ X1 + (1|group),
                     tune_RF = FALSE)

# XGB

obj_p_score_XGB <- list(data_p_score = populations)
class(obj_p_score_XGB) <- "XGB"

ps_hat_XGB <-  p_score(obj_p_score = obj_p_score_XGB,
                       model_formula = A ~ X1 + (1|group),
                       xgboost_params = list(CV_XGB = FALSE,
                                             nfolds = 5,
                                             nrounds = 50))



}
